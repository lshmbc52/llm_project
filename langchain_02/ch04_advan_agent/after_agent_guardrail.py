import common_utils_solar as utils
from langchain.agents.middleware import after_agent
from langchain.messages import HumanMessage, SystemMessage,AIMessage
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model

safety_model = utils.get_solar_model(model_name='solar-pro')

@after_agent
def answer_leakage_guardrail(state,runtime):
    """
    AIê°€ ë‹µë³€ì„ ìƒì„±í•œ 'ì§í›„', ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ì „ì— ë‚´ìš©ì„ ê²€ì‚¬.
    ë§Œì•½ AIê°€ ë¬¸ì œì˜ ì •ë‹µì„ ì§ì ‘ì ìœ¼ë¡œ ë§í•´ë²„ë ¸ë‹¤ë©´, ì´ë¥¼ ê°ì§€í•˜ê³  ìˆ˜ì •.
    """
    if not state["messages"]: return None
    
    last_message = state["messages"][-1]

    if not isinstance(last_message,AIMessage):
        return None

    auditor_prompt =f"""
        ë‹¹ì‹ ì€ ì—„ê²©í•œ êµìœ¡ ê°ë…ê´€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ 'íŠœí„°ì˜ ë‹µë³€'ì„ í™•ì¸í•˜ì„¸ìš”.
        ë‹µë³€ì´ í•™ìƒì„ ì§€ë„í•˜ì§€ ì•Šê³  ë¬¸ì œì˜ ì •ë‹µì´ë‚˜ ì „ì²´ í’€ì´ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì œê³µí•œë‹¤ë©´ 'LEAKED'ë¼ê³  ë‹µí•˜ì„¸ìš”.
        ë‹µë³€ì´ ì ì ˆí•œ íŒíŠ¸ë‚˜ ì„¤ëª…ì„ ì œê³µí•œë‹¤ë©´ 'SAFE'ë¼ê³  ë‹µí•˜ì„¸ìš”.

        íŠœí„°ì˜ ë‹µë³€: {last_message.content}
        """

    result = safety_model.invoke(auditor_prompt)

    if "LEAKED" in result.content:
        print(f"[ê°€ë“œë ˆì¼ ë°œë™] ì •ë‹µ ìœ ì¶œ ê°ì§€ë¨!. ë‹µë³€ì„ ìˆ˜ì •í•©ë‹ˆë‹¤")
        print(f"ê¸°ì¡´ ë‹µë³€:{last_message.content}")
        last_message.content = "ì•—, ì œê°€ ì •ë‹µì„ ë°”ë¡œ ë§í•  ë»”í–ˆë„¤ìš”! ğŸ˜… ì •ë‹µë³´ë‹¤ëŠ” í‘¸ëŠ” ë°©ë²•ì„ ë¨¼ì € ìƒê°í•´ë³¼ê¹Œìš”? ì´ ë¬¸ì œì˜ í•µì‹¬ ê°œë…ì€..."
    return None

agent = create_agent(
    model = 'solar-pro',
    tools =[],
    middleware=[answer_leakage_guardrail],
)

response = agent.invoke({
    "messages":[{"role":"user","content":"ì§ê° ì‚¼ê°í˜• ë‘ ì§ê°ë³€ì˜ ê¸¸ì´ê°€ 3ê³¼ 4ë¼ë©´ ë¹—ë³€ì˜ ê¸¸ì´ê°€ ë­ì•¼? ì´ ë¬¸ì œ ë„ˆë¬´ ì–´ë ¤ì›Œ. ê·¸ëƒ¥ ì •ë‹µ ì•Œë ¤ì¤˜"}]
})

print(response)
print("-----------------------------")

@after_agent
def answer_leakage_guardrail(state,runtime):
    """
    AIê°€ ë‹µë³€ì„ ìƒì„±í•œ 'ì§í›„', ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ì „ì— ë‚´ìš©ì„ ê²€ì‚¬.
    ë§Œì•½ AIê°€ ë¬¸ì œì˜ ì •ë‹µì„ ì§ì ‘ì ìœ¼ë¡œ ë§í•´ë²„ë ¸ë‹¤ë©´, ì´ë¥¼ ê°ì§€í•˜ê³  ìˆ˜ì •.
    """
    if not state["messages"]: return None
    last_messages = state["messages"][-1]
    if not isinstance(last_messages, AIMessages):
        return None
    
    auditor_prompt = f"""
    ë‹¹ì‹ ì€ ì—„ê²©í•œ êµìœ¡ ê°ë…ê´€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ 'íŠœí„°ì˜ ë‹µë³€'ì„ í™•ì¸í•˜ì„¸ìš”.
    ë‹µë³€ì´ í•™ìƒì„ ì§€ë„í•˜ì§€ ì•Šê³  ë¬¸ì œì˜ ì •ë‹µì´ë‚˜ ì „ì²´ í’€ì´ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì œê³µí•œë‹¤ë©´ 'LEAKED'ë¼ê³  ë‹µí•˜ì„¸ìš”.
    ë‹µë³€ì´ ì ì ˆí•œ íŒíŠ¸ë‚˜ ì„¤ëª…ì„ ì œê³µí•œë‹¤ë©´ 'SAFE'ë¼ê³  ë‹µí•˜ì„¸ìš”.
    íŠœí„°ì˜ ë‹µë³€: {last_message.content}
    """

    result = safety_model.inovoke(auditor_prompt)

    if "LEAKED" in result.content:
        from langchain.agents.middleware import after_agent


@after_agent
def answer_leakage_guardrail(state, runtime):
    """
    AIê°€ ë‹µë³€ì„ ìƒì„±í•œ 'ì§í›„', ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ì „ì— ë‚´ìš©ì„ ê²€ì‚¬.
    ë§Œì•½ AIê°€ ë¬¸ì œì˜ ì •ë‹µì„ ì§ì ‘ì ìœ¼ë¡œ ë§í•´ë²„ë ¸ë‹¤ë©´, ì´ë¥¼ ê°ì§€í•˜ê³  ìˆ˜ì •.
    """

    # 1. ë©”ì‹œì§€ ìœ íš¨ì„± ê²€ì‚¬
    if not state["messages"]: return None
    last_message = state["messages"][-1]

    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ AIì˜ ë‹µë³€ì´ ì•„ë‹ˆë©´ ê²€ì‚¬í•  í•„ìš” ì—†ìŒ
    if not isinstance(last_message, AIMessage):
        return None

    # 2. ê°ì‹œì AIì—ê²Œ í‰ê°€ ìš”ì²­ (Prompt Engineering)
    # ë©”ì¸ AIì˜ ë‹µë³€ì´ êµìœ¡ì ìœ¼ë¡œ ì ì ˆí•œì§€(ì •ë‹µì„ ë°”ë¡œ ì£¼ì§€ ì•Šì•˜ëŠ”ì§€) í‰ê°€í•©ë‹ˆë‹¤.
    auditor_prompt = f"""
    ë‹¹ì‹ ì€ ì—„ê²©í•œ êµìœ¡ ê°ë…ê´€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ 'íŠœí„°ì˜ ë‹µë³€'ì„ í™•ì¸í•˜ì„¸ìš”.
    ë‹µë³€ì´ í•™ìƒì„ ì§€ë„í•˜ì§€ ì•Šê³  ë¬¸ì œì˜ ì •ë‹µì´ë‚˜ ì „ì²´ í’€ì´ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì œê³µí•œë‹¤ë©´ 'LEAKED'ë¼ê³  ë‹µí•˜ì„¸ìš”.
    ë‹µë³€ì´ ì ì ˆí•œ íŒíŠ¸ë‚˜ ì„¤ëª…ì„ ì œê³µí•œë‹¤ë©´ 'SAFE'ë¼ê³  ë‹µí•˜ì„¸ìš”.
    íŠœí„°ì˜ ë‹µë³€: {last_message.content}
    """

    result = safety_model.invoke([{"role": "user", "content": auditor_prompt}])

    # 3ë‹¨ê³„: êµì • (Correction / Regeneration)
    if "LEAKED" in result.content:

        # ì›ë˜ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ê¸° (ë¬¸ë§¥ íŒŒì•…ìš©) -> state["messages"][-2]ê°€ ë³´í†µ ì‚¬ìš©ì ì§ˆë¬¸
        original_question = state["messages"][-2].content if len(state["messages"]) >= 2 else "ì‚¬ìš©ì ì§ˆë¬¸ ì•Œ ìˆ˜ ì—†ìŒ"

        # êµì • ëª¨ë¸ì—ê²Œ "ì •ë‹µì„ ë¹¼ê³  íŒíŠ¸ë¡œ ë°”ê¿”ë¼"ê³  ì§€ì‹œ
        correction_prompt = f"""
        ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI íŠœí„°ì…ë‹ˆë‹¤.

        ì ˆëŒ€ ì •ë‹µì„ ì§ì ‘ ë§í•˜ì§€ ë§ê³ , í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ìƒê°í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ í•µì‹¬ ê°œë…(íŒíŠ¸)ë§Œ ì„¤ëª…í•˜ì„¸ìš”.
        ë§íˆ¬ëŠ” ì¹œì ˆí•˜ê²Œ í•´ì£¼ì„¸ìš”.

        ì‚¬ìš©ì ì§ˆë¬¸: {original_question}
        """

        # LLMì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ë‹µë³€ ìƒì„± (ë¹„ìš©ì€ 1íšŒ ë” ë°œìƒí•˜ì§€ë§Œ í’ˆì§ˆ í™•ë³´)
        corrected_response = safety_model.invoke([
            SystemMessage(content="ë‹¹ì‹ ì€ ì†Œí¬ë¼í…ŒìŠ¤ì‹ êµìœ¡ë²•ì„ ì‚¬ìš©í•˜ëŠ” íŠœí„°ì…ë‹ˆë‹¤."),
            HumanMessage(content=correction_prompt)
        ])

        # ì›ë˜ì˜ ìœ ì¶œëœ ë‹µë³€ì„ êµì •ëœ ë‹µë³€ìœ¼ë¡œ ë®ì–´ì“°ê¸°
        last_message.content = corrected_response.content

    return None

agent = create_agent(
    model ='solar-pro',
    tools =[],
    middleware =[answer_leakage_guardrail],
)

if __name__=="__main__":

    result = agent.invoke(
        {
        "messages": [{"role": "user", "content": "ì§ê° ì‚¼ê°í˜• ë‘ ì§ê°ë³€ì˜ ê¸¸ì´ê°€ 3ê³¼ 4ë¼ë©´ ë¹—ë³€ì˜ ê¸¸ì´ê°€ ë­ì•¼? ì´ ë¬¸ì œ ë„ˆë¬´ ì–´ë ¤ì›Œ. ê·¸ëƒ¥ ì •ë‹µ ì•Œë ¤ì¤˜."}]
        },
    )

    print(result)

