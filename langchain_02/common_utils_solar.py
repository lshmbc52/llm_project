import os
import gc
import torch
from contextlib import contextmanager
from langchain_upstage import ChatUpstage  # Upstage ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
from contextlib import contextmanager
from typing import List, Dict, Any


@contextmanager
def memory_cleanup():
    """GPU ë° ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    try:
        yield
    finally:
        # GPU ìºì‹œ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("GPU ìºì‹œ ë¹„ìš°ê¸° ì™„ë£Œ (Upstage ëª¨ë“œ)")

        gc.collect()
        print("ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")


def get_solar_model(model_name="solar-pro", temperature=0.5, **kwargs):
    """
    Upstage Solar ëª¨ë¸ ê°ì²´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    í™˜ê²½ë³€ìˆ˜ UPSTAGE_API_KEYë¥¼ ìë™ìœ¼ë¡œ ì°¸ì¡°í•©ë‹ˆë‹¤.
    """
    # .bashrcì— ë“±ë¡í•œ í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    api_key = os.getenv("UPSTAGE_API_KEY")

    return ChatUpstage(
        model=model_name, upstage_api_key=api_key, temperature=temperature, **kwargs
    )


if __name__ == "__main__":
    print("-- Upstage Solar ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘ --")

    # í™˜ê²½ë³€ìˆ˜ ì²´í¬
    if not os.getenv("UPSTAGE_API_KEY"):
        print("ğŸš¨ ê²½ê³ : UPSTAGE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        model = get_solar_model()
        print(f"âœ… ë¡œë“œëœ ëª¨ë¸: {model.model}")

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œ
        # response = model.invoke("ì•ˆë…•, ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ?")
        # print(f"í…ŒìŠ¤íŠ¸ ì‘ë‹µ: {response.content}")

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
