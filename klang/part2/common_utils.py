import os
import gc
from contextlib import contextmanager
from typing import List, Dict, Any

# torchê°€ ì—†ì–´ë„ ì—ëŸ¬ë‚˜ì§€ ì•Šê²Œ ë³´í˜¸ë§‰ ìƒì„±!
try:
    import torch
except ImportError:
    torch = None

from langchain_upstage import ChatUpstage
from langchain_openai import ChatOpenAI

@contextmanager
def memory_cleanup():
    """GPU ë° ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    try:
        yield
    finally:
        # torchê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  CUDA(GPU)ë¥¼ ì“¸ ìˆ˜ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        if torch is not None and torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPU ìºì‹œ ë¹„ìš°ê¸° ì™„ë£Œ")
        gc.collect()
        print("âœ¨ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

def get_gpt_model(model_name="gpt-4o-mini", temperature=0.5, **kwargs):
    """OpenAI GPT ëª¨ë¸ í˜¸ì¶œ"""
    return ChatOpenAI(model=model_name, temperature=temperature, **kwargs)

def get_solar_model(model_name="solar-pro", temperature=0.5, **kwargs):
    """Upstage Solar ëª¨ë¸ í˜¸ì¶œ"""
    api_key = os.getenv("UPSTAGE_API_KEY")
    return ChatUpstage(model=model_name, upstage_api_key=api_key, temperature=temperature, **kwargs)

if __name__ == "__main__":
    print("\n-- ğŸš€ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘ --")

    try:
        with memory_cleanup():
            gpt_model = get_gpt_model()
            solar_model = get_solar_model()

            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ì†ì„± ì´ë¦„ì´ ë¬´ì—‡ì´ë“  ìƒê´€ì—†ì´ ëª¨ë¸ëª…ì„ ê°€ì ¸ì˜¤ëŠ” ë§ˆë²•!
            def get_name(m):
                # model_name ë¨¼ì € ì°¾ì•„ë³´ê³ , ì—†ìœ¼ë©´ model ì°¾ì•„ë³´ê³ , ê·¸ê²ƒë„ ì—†ìœ¼ë©´ 'Unknown'
                return getattr(m, 'model_name', None) or getattr(m, 'model', 'Unknown')

            print(f"âœ… GPT ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {get_name(gpt_model)}")
            print(f"âœ… Solar ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {get_name(solar_model)}")
            print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")