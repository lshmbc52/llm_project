import os
import gc
from dotenv import load_dotenv

# current_dir = os.path.dirname(os.path.abspath(__file__))
# dotenv_path = os.path.join(current_dir, "../.env")

# load_dotenv(dotenv_path)

from contextlib import contextmanager

# from typing import List, Dict, Any

# torchê°€ ì—†ì–´ë„ ì—ëŸ¬ë‚˜ì§€ ì•Šê²Œ ë³´í˜¸ë§‰ ìƒì„±!
try:
    import torch
except ImportError:
    torch = None

from langchain_upstage import ChatUpstage
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_google_genai import ChatGoogleGenerativeAI


@contextmanager
def memory_cleanup():
    """GPU ë° ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    try:
        yield
    finally:
        # torchê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  CUDA(GPU)ë¥¼ ì“¸ ìˆ˜ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        if torch is not None and torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPU ìºì‹œ ë¹„ìš°ê¸° ì™„ë£Œ")
        gc.collect()
        print("âœ¨ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")


def get_gemini_model(model_name="gemini-3-flash-preview", temperature=0.5, **kwargs):
    """Gemini 3 ëª¨ë¸ í˜¸ì¶œ"""
    api_key = os.getenv("GEMINI_API_KEY")
    return ChatGoogleGenerativeAI(
        model=model_name,
        temperature=temperature,
        **kwargs,
        google_api_key=api_key,
    )


def get_gpt_model(model_name="gpt-4o-mini", temperature=0.5, **kwargs):
    """OpenAI GPT ëª¨ë¸ í˜¸ì¶œ"""
    return ChatOpenAI(model=model_name, temperature=temperature, **kwargs)


def get_solar_model(model_name="solar-pro", temperature=0.5, **kwargs):
    """Upstage Solar ëª¨ë¸ í˜¸ì¶œ"""
    api_key = os.getenv("UPSTAGE_API_KEY")
    return ChatUpstage(
        model=model_name, upstage_api_key=api_key, temperature=temperature, **kwargs
    )


def get_exaone_model(model_name="exaone3.5:2.4b", temperature=0.5, **kwargs):
    """Ollamaë¥¼ í†µí•œ EXAONE ëª¨ë¸ í˜¸ì¶œ"""
    # ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ API Keyê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
    return ChatOllama(model=model_name, temperature=temperature, **kwargs)


if __name__ == "__main__":
    print("\n-- ğŸš€ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘ --")

    try:
        with memory_cleanup():
            gemini_model = get_gemini_model()
            gpt_model = get_gpt_model()
            solar_model = get_solar_model()
            exaone_model = get_exaone_model()

            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ì†ì„± ì´ë¦„ì´ ë¬´ì—‡ì´ë“  ìƒê´€ì—†ì´ ëª¨ë¸ëª…ì„ ê°€ì ¸ì˜¤ëŠ” ë§ˆë²•!
            def get_name(m):
                # model_name ë¨¼ì € ì°¾ì•„ë³´ê³ , ì—†ìœ¼ë©´ model ì°¾ì•„ë³´ê³ , ê·¸ê²ƒë„ ì—†ìœ¼ë©´ 'Unknown'
                return getattr(m, "model_name", None) or getattr(m, "model", "Unknown")

            print(f"âœ… GPT ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {get_name(gpt_model)}")
            print(f"âœ… Solar ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {get_name(solar_model)}")
            print(f"âœ… Exaone ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {get_name(exaone_model)}")
            print(f"âœ… Gemini ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {get_name(gemini_model)}")
            print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
